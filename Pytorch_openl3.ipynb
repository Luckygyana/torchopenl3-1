{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AbFP80mQ2WY"
      },
      "source": [
        "import torch\r\n",
        "import torch.utils.data as data\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "import librosa\r\n",
        "import soundfile as sf\r\n",
        "import numpy as np\r\n",
        "import cv2\r\n",
        "\r\n",
        "from fastprogress import progress_bar"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcXcq3aqao0L"
      },
      "source": [
        "class Dataset(data.Dataset):\r\n",
        "    def __init__(self,audio_list):\r\n",
        "        self.audio_list = audio_list\r\n",
        "        self.n_dft = 2048\r\n",
        "        self.n_mels = 128\r\n",
        "        self.n_hop = 242\r\n",
        "        self.asr = 48000\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.audio_list)\r\n",
        "   \r\n",
        "    def __getitem__(self, idx: int):\r\n",
        "        audio = audio_list[idx]\r\n",
        "        melspec_librosa = librosa.feature.melspectrogram(audio,sr=self.asr,n_fft=self.n_dft,\r\n",
        "                                hop_length=self.n_hop,win_length=None,center=True,power=2.0,n_mels=self.n_mels,\r\n",
        "                                norm='slaney',htk=True)\r\n",
        "        image = self.norm_func(melspec_librosa)\r\n",
        "        image = cv2.resize(melspec_librosa, (199,128))\r\n",
        "        image = np.reshape(image,(128,199,1))\r\n",
        "        image = np.moveaxis(image, 2, 0)\r\n",
        "        image = (image / 255.0).astype(np.float32)\r\n",
        "        return image\r\n",
        "    def norm_func(self,X: np.ndarray,mean=None,std=None,\r\n",
        "                  norm_max=None,norm_min=None,eps=1e-6):\r\n",
        "\r\n",
        "        mean = mean or X.mean()\r\n",
        "        X = X - mean\r\n",
        "        std = std or X.std()\r\n",
        "        Xstd = X / (std + eps)\r\n",
        "        _min, _max = Xstd.min(), Xstd.max()\r\n",
        "        norm_max = norm_max or _max\r\n",
        "        norm_min = norm_min or _min\r\n",
        "        if (_max - _min) > eps:\r\n",
        "            V = Xstd\r\n",
        "            V[V < norm_min] = norm_min\r\n",
        "            V[V > norm_max] = norm_max\r\n",
        "            V = 255 * (V - norm_min) / (norm_max - norm_min)\r\n",
        "            V = V.astype(np.uint8)\r\n",
        "        else:\r\n",
        "            V = np.zeros_like(Xstd, dtype=np.uint8)\r\n",
        "        return V"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecp2C7ZB-A38"
      },
      "source": [
        "audio, _ = sf.read('/content/Fanfare60.wav')\r\n",
        "audio_list = [audio]\r\n",
        "dataset = Dataset(audio_list=audio_list)\r\n",
        "loader = data.DataLoader(dataset, batch_size=10, shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KptWg1GISbg7"
      },
      "source": [
        "class Model(torch.nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Model, self).__init__()\r\n",
        "        self.BN1 = torch.nn.BatchNorm2d(1)\r\n",
        "\r\n",
        "        self.C1 = torch.nn.Conv2d(1,64,3,padding=1)\r\n",
        "        self.BN2 = torch.nn.BatchNorm2d(64)\r\n",
        "        self.C2 = torch.nn.Conv2d(64,64,3,padding=1)\r\n",
        "        self.BN3 = torch.nn.BatchNorm2d(64)\r\n",
        "        self.maxpool1 = torch.nn.MaxPool2d(2,2)\r\n",
        "\r\n",
        "        self.C3 = torch.nn.Conv2d(64,128,3,padding=1)\r\n",
        "        self.BN4 = torch.nn.BatchNorm2d(128)\r\n",
        "        self.C4 = torch.nn.Conv2d(128,128,3,padding=1)\r\n",
        "        self.BN5 = torch.nn.BatchNorm2d(128)\r\n",
        "        self.maxpool2 = torch.nn.MaxPool2d(2,2)\r\n",
        "\r\n",
        "        self.C5 = torch.nn.Conv2d(128,256,3,padding=1)\r\n",
        "        self.BN6 = torch.nn.BatchNorm2d(256)\r\n",
        "        self.C6 = torch.nn.Conv2d(256,256,3,padding=1)\r\n",
        "        self.BN7 = torch.nn.BatchNorm2d(256)\r\n",
        "        self.maxpool3 = torch.nn.MaxPool2d(2,2)\r\n",
        "\r\n",
        "        self.C7 = torch.nn.Conv2d(256,512,3,padding=1)\r\n",
        "        self.BN8 = torch.nn.BatchNorm2d(512)\r\n",
        "        self.C8 = torch.nn.Conv2d(512,512,3,padding=1)\r\n",
        "        self.BN9 = torch.nn.BatchNorm2d(512)\r\n",
        "        \r\n",
        "        self.C9 = torch.nn.Conv2d(512,512,3,padding=1)\r\n",
        "\r\n",
        "        self.maxpool4 = torch.nn.MaxPool2d(kernel_size=(4,8))\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.BN1(x)\r\n",
        "\r\n",
        "        x = F.relu(self.BN2(self.C1(x)))\r\n",
        "        x = F.relu(self.BN3(self.C2(x)))\r\n",
        "        x = self.maxpool1(x)\r\n",
        "\r\n",
        "        x = F.relu(self.BN4(self.C3(x)))\r\n",
        "        x = F.relu(self.BN5(self.C4(x)))\r\n",
        "        x = self.maxpool2(x)\r\n",
        "\r\n",
        "        x = F.relu(self.BN6(self.C5(x)))\r\n",
        "        x = F.relu(self.BN7(self.C6(x)))\r\n",
        "        x = self.maxpool3(x)\r\n",
        "\r\n",
        "        x = F.relu(self.BN8(self.C7(x)))\r\n",
        "        x = F.relu(self.BN9(self.C8(x)))\r\n",
        "        x = self.C9(x)\r\n",
        "\r\n",
        "        x = self.maxpool4(x)\r\n",
        "        x = torch.flatten(x,start_dim=1)\r\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT-IRegb_BhJ"
      },
      "source": [
        "model = Model()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "VbjawX0q_DR4",
        "outputId": "80177b31-11c1-4935-aac5-6cce4474e656"
      },
      "source": [
        "for audio in progress_bar(loader):\r\n",
        "    pred = model(audio)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [1/1 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjMJkb5m_mwF",
        "outputId": "face087f-beca-45e5-a09c-18a570fd4c8e"
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6144])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}